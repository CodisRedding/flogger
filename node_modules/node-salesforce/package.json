{
  "author": {
    "name": "Shinichi Tomita",
    "email": "shinichi.tomita@gmail.com"
  },
  "name": "node-salesforce",
  "description": "Salesforce API Connection Library for Node.js Applications",
  "keywords": [
    "salesforce",
    "salesforce.com",
    "sfdc",
    "force.com",
    "database.com"
  ],
  "homepage": "http://github.com/stomita/node-salesforce",
  "version": "0.5.1",
  "repository": {
    "type": "git",
    "url": "git://github.com/stomita/node-salesforce.git"
  },
  "licenses": [
    {
      "type": "MIT",
      "url": "http://github.com/stomita/node-salesforce/raw/master/LICENSE"
    }
  ],
  "main": "./lib/salesforce",
  "scripts": {
    "test": "vows test/*.test.js --spec"
  },
  "engines": {
    "node": ">=0.4.0"
  },
  "dependencies": {
    "async": "0.1.x",
    "request": "2.12.x",
    "underscore": "1.4.x",
    "xml2json": "0.3.2",
    "faye": "0.8.x"
  },
  "devDependencies": {
    "express": "2.5.x",
    "vows": "0.7.x",
    "zombie": "1.4.1"
  },
  "readme": "# node-salesforce -- Salesforce API Connection Library for Node.js Applications\n\n[![Build Status](https://secure.travis-ci.org/stomita/node-salesforce.png?branch=travis-ci)](http://travis-ci.org/stomita/node-salesforce)\n\n## Abstract\n\nNode-salesforce, which is designed to be a wrapper of Salesforce REST API in Node.js, enables Salesforce application development in event-driven style.\nIt capsulates the access to REST API end point in asynchronous JavaScript function call.\nYou can use both OAuth2 access token and SOAP login sessionId for API authentication.\n\n\n## Install\n\n<pre>\n  npm install node-salesforce\n</pre>\n\nor\n\n<pre>\n  git clone git://github.com/stomita/node-salesforce.git \n  cd node-salesforce\n  npm link\n</pre>\n\n\n## Establish Connection \n\n### Using Session ID\n\n```javascript\nvar sf = require('node-salesforce');\nvar conn = new sf.Connection({\n  serverUrl : '<your Salesforce server URL (e.g. https://na1.salesforce.com) is here>',\n  sessionId : '<your Salesforce session ID is here>'\n});\n```\n\n### Using OAuth2 Access Token\n\n```javascript\nvar sf = require('node-salesforce');\nvar conn = new sf.Connection({\n  instanceUrl : '<your Salesforce server URL (e.g. https://na1.salesforce.com) is here>',\n  accessToken : '<your Salesforrce OAuth2 access token is here>'\n});\n```\n\n### Using OAuth2 Access Token with Refresh Token (automatically refresh access token when expired)\n\n```javascript\nvar sf = require('node-salesforce');\nvar conn = new sf.Connection({\n  oauth2 : {\n    clientId : '<your Salesforce OAuth2 client ID is here>',\n    clientSecret : '<your Salesforce OAuth2 client secret is here>',\n    redirectUri : '<your Salesforce OAuth2 redirect URI is here>'\n  },\n  instanceUrl : '<your Salesforce server URL (e.g. https://na1.salesforce.com) is here>',\n  accessToken : '<your Salesforrce OAuth2 access token is here>',\n  refreshToken : '<your Salesforce OAuth2 refresh token is here>'\n});\nconn.on(\"refresh\", function(accessToken, res) {\n  // Refresh event will be fired when renewed access token\n  // to store it in your storage for next request\n});\n```\n\n\n### Username and Password Login (SOAP API)\n\n```javascript\nvar sf = require('node-salesforce');\nvar conn = new sf.Connection({\n  // you can change loginUrl to connect to sandbox or prerelease env.\n  // loginUrl : 'https://test.salesforce.com'\n});\nconn.login(username, password, function(err, userInfo) {\n  if (err) { return console.error(err); }\n  console.log(conn.accessToken);\n  console.log(\"User ID: \" + userInfo.id);\n  console.log(\"Org ID: \" + userInfo.organizationId);\n  // ...\n});\n```\n\n### Username and Password Login (OAuth2 Resource Owner Password Credential)\n\n```javascript\nvar sf = require('node-salesforce');\nvar conn = new sf.Connection({\n  oauth2 : {\n    // you can change loginUrl to connect to sandbox or prerelease env.\n    // loginUrl : 'https://test.salesforce.com',\n    clientId : '<your Salesforce OAuth2 client ID is here>',\n    clientSecret : '<your Salesforce OAuth2 client secret is here>',\n    redirectUri : '<callback URI is here>'\n  }\n});\nconn.login(username, password, function(err, userInfo) {\n  if (err) { return console.error(err); }\n  console.log(conn.accessToken);\n  console.log(\"User ID: \" + userInfo.id);\n  console.log(\"Org ID: \" + userInfo.organizationId);\n  // ...\n});\n```\n\n### Logout (Only for SOAP API session)\n\n```javascript\nvar sf = require('node-salesforce');\nvar conn = new sf.Connection({\n  sessionId : '<session id to logout>',\n  serverUrl : '<your Salesforce Server url to logout is here>'\n});\nconn.logout(function(err) {\n  if (err) { return console.error(err); }\n  // now the session has been expired.\n});\n```\n\n## OAuth2 Web Server Flow\n\n### Authorization Request\n\nFollowing example is using express.js framework\n\n```javascript\nvar sf = require('node-salesforce');\n\n// OAuth2 client information can be shared with multiple connections.\nvar oauth2 = new sf.OAuth2({\n  // you can change loginUrl to connect to sandbox or prerelease env.\n  // loginUrl : 'https://test.salesforce.com',\n  clientId : '<your Salesforce OAuth2 client ID is here>',\n  clientSecret : '<your Salesforce OAuth2 client secret is here>',\n  redirectUri : '<callback URI is here>'\n});\n\n// get authz url and redirect to it.\napp.get('/oauth2/auth', function(req, res) {\n  res.redirect(oauth2.getAuthorizationUrl({ scope : 'api id web' }));\n});\n```\n\n### Access Token Request\n\n```javascript\n// pass received authz code and get access token\napp.get('/oauth2/callback', function(req, res) {\n  var conn = new sf.Connection({ oauth2 : oauth2 });\n  var code = req.param('code');\n  conn.authorize(code, function(err, userInfo) {\n    if (err) { return console.error(err); }\n    console.log(conn.accessToken);\n    console.log(\"User ID: \" + userInfo.id);\n    console.log(\"Org ID: \" + userInfo.organizationId);\n    // ...\n  });\n});\n```\n\n\n## Query Records\n\n### Using SOQL\n\n#### Event-Driven Style\n\n```javascript\nvar records = [];\nconn.query(\"SELECT Id, Name FROM Account\")\n  .on(\"record\", function(record) {\n    records.push(record);\n  })\n  .on(\"end\", function(query) {\n    console.log(\"total in database : \" + query.totalSize);\n    console.log(\"total fetched : \" + query.totalFetched);\n  })\n  .on(\"error\", function(err) {\n    console.error(err);\n  })\n  .run({ autoFetch : true, maxFetch : 4000 });\n```\n\n#### Callback Style\n\n```javascript\nvar records = [];\nconn.query(\"SELECT Id, Name FROM Account\", function(err, result) {\n  if (err) { return console.error(err); }\n  console.log(\"total : \" + result.totalSize);\n  console.log(\"fetched : \" + result.records.length);\n});\n```\n\n### Using JSON-style Query object and method chaining (like MongoDB)\n\n```javascript\n// following query is equivalent to this SOQL\n// \"SELECT Id, Name, CreatedDate FROM Contact\n//  WHERE LastName LIKE 'A%' AND CreatedDate >= YESTERDAY AND Account.Name = 'Sony, Inc.'\n//  ORDER BY CreatedDate DESC, Name ASC\n//  LIMIT 5 OFFSET 10\"\nconn.sobject(\"Contact\")\n  .find({\n    LastName : { $like : 'A%' },\n    CreatedDate: { $gte : sf.Date.YESTERDAY },\n    'Account.Name' : 'Sony, Inc.'\n  }, {\n    Id: 1,\n    Name: 1,\n    CreatedDate: 1\n  })\n  .sort({ CreatedDate: -1, Name : 1 })\n  .limit(5)\n  .skip(10)\n  .execute(function(err, result) {\n    if (err) { return console.error(err); }\n    console.log(\"total : \" + result.totalSize);\n    console.log(\"fetched : \" + result.records.length);\n  });\n```\n\n## CRUD Operation\n\n### Retrieve\n\n```javascript\nconn.sobject(\"Account\").retrieve(\"0017000000hOMChAAO\", function(err, account) {\n  if (err) { return console.error(err); }\n  console.log(\"Name : \" + account.Name);\n  // ...\n});\n\n// Multiple records retrieval consumes one API request per record.\n// Be careful for the API quota.\nconn.sobject(\"Account\").retrieve([\"0017000000hOMChAAO\", \"0017000000iKOZTAA4\"], function(err, accounts) {\n  if (err) { return console.error(err); }\n  for (var i=0; i < accounts.length; i++) {\n    console.log(\"Name : \" + accounts[i].Name);\n  }\n  // ...\n});\n```\n\n### Create \n\n```javascript\nconn.sobject(\"Account\").create({ Name : 'My Account #1' }, function(err, ret) {\n  if (err || !ret.success) { return console.error(err, ret); }\n  console.log(\"Created record id : \" + ret.id);\n  // ...\n});\n// Multiple records creation consumes one API request per record.\n// Be careful for the API quota.\nconn.sobject(\"Account\").create([\n  { Name : 'My Account #1' },\n  { Name : 'My Account #2' }\n],\nfunction(err, rets) {\n  if (err) { return console.error(err); }\n  for (var i=0; i < rets.length; i++) {\n    if (rets[i].success) {\n      console.log(\"Created record id : \" + rets[i].id);\n    }\n  }\n  // ...\n});\n```\n\n### Update\n\n```javascript\nconn.sobject(\"Account\").update({ \n  Id : '0017000000hOMChAAO',\n  Name : 'Updated Account #1'\n}, function(err, ret) {\n  if (err || !ret.success) { return console.error(err, ret); }\n  console.log('Updated Successfully : ' + ret.id);\n  // ...\n});\n\n// Multiple records modification consumes one API request per record.\n// Be careful for the API quota.\nconn.sobject(\"Account\").update([\n  { Id : '0017000000hOMChAAO', Name : 'Updated Account #1' },\n  { Id : '0017000000iKOZTAA4', Name : 'Updated Account #2' }\n],\nfunction(err, rets) {\n  if (err) { return console.error(err); }\n  for (var i=0; i < rets.length; i++) {\n    if (rets[i].success) {\n      console.log(\"Updated Successfully : \" + rets[i].id);\n    }\n  }\n});\n```\n\n### Delete\n\n```javascript\nconn.sobject(\"Account\").del('0017000000hOMChAAO', function(err, ret) {\n  if (err || !ret.success) { return console.error(err, ret); }\n  console.log('Deleted Successfully : ' + ret.id);\n});\n\n// Multiple records deletion consumes one API request per record.\n// Be careful for the API quota.\nconn.sobject(\"Account\").destroy([ // synonym of \"del\"\n  '0017000000hOMChAAO',\n  '0017000000iKOZTAA4'\n}], \nfunction(err, rets) {\n  if (err) { return console.error(err); }\n  for (var i=0; i < rets.length; i++) {\n    if (rets[i].success) {\n      console.log(\"Deleted Successfully : \" + rets[i].id);\n    }\n  }\n});\n```\n\n\n### Upsert\n\n```javascript\nconn.sobject(\"UpsertTable__c\").upsert({ \n  Name : 'Record #1',\n  ExtId__c : 'ID-0000001'\n}, 'ExtId__c', function(err, ret) {\n  if (err || !ret.success) { return console.error(err, ret); }\n  console.log('Upserted Successfully');\n  // ...\n});\n// Multiple records modification consumes one API request per record.\n// Be careful for the API quota.\nconn.sobject(\"UpsertTable__c\").upsert([\n { Name : 'Record #1', ExtId__c : 'ID-0000001' },\n { Name : 'Record #2', ExtId__c : 'ID-0000002' }\n],\n'ExtId__c',\nfunction(err, rets) {\n  if (err) { return console.error(err); }\n  for (var i=0; i < rets.length; i++) {\n    if (rets[i].success) {\n      console.log(\"Upserted Successfully\");\n    }\n  }\n  // ...\n});\n```\n\n\n## Describe\n\n### SObject\n\n```javascript\nconn.sobject(\"Account\").describe(function(err, meta) {\n  if (err) { return console.error(err); }\n  console.log('Label : ' + meta.label);\n  console.log('Num of Fields : ' + meta.fields.length);\n  // ...\n});\n```\n\n### Global Object\n\n```javascript\nconn.describeGlobal(function(err, res) {\n  if (err) { return console.error(err); }\n  console.log('Num of SObjects : ' + res.sobjects.length);\n  // ...\n});\n```\n\n## Streaming\n\n```javascript\n/**\n Before the subscription, you should insert appropriate PushTopic record (in this example, \"InvoiceStatementUpdates\") as written in Streaming API guide.\n */\nconn.topic(\"InvoiceStatementUpdates\").subscribe(function(message) {\n  console.log('Event Type : ' + message.event.type);\n  console.log('Event Created : ' + message.event.createdDate);\n  console.log('Object Id : ' + message.sobject.Id);\n});\n```\n\n\n## Bulk Operation\n\n### Loading records\n\n```javascript\n// Records to insert in bulk.\nvar accounts = [\n{ Name : 'Account #1', ... }, \n{ Name : 'Account #2', ... }, \n{ Name : 'Account #3', ... }, \n...\n];\n\n// Create bulkload job and add batch to execute loading,\nvar job = conn.bulk.createJob(\"Account\", \"insert\");\nvar batch = job.createBatch();\nbatch.on(\"queue\", function(batchInfo) { // fired when batch request is queued in server.\n  batchId = batchInfo.id);\n  jobId = batchInfo.jobId);\n  // ...\n});\nbatch.execute(accounts);\n\n// and check the status later.\nvar job = conn.bulk.job(jobId);\nvar batch = job.batch(batchId);\nbatch.poll(1000 /* interval(ms) */, 20000 /* timeout(ms) */); // start polling\nbatch.on(\"response\", function(rets) { // fired when batch finished and result retrieved\n  if (err) { return console.error(err); }\n  for (var i=0; i < rets.length; i++) {\n    if (rets[i].success) {\n      console.log(\"#\" + (i+1) + \" loaded successfully, id = \" + rets[i].id);\n    } else {\n      console.log(\"#\" + (i+1) + \" error occurred, message = \" + rets[i].errors.join(', '));\n    }\n  }\n  // ...\n});\n\n// or use Bulk#load() method in one call to upload records and fetch results. \nconn.bulk.load(\"Account\", \"insert\", accounts, function(err, rets) {\n  if (err) { return console.error(err); }\n  for (var i=0; i < rets.length; i++) {\n    if (rets[i].success) {\n      console.log(\"#\" + (i+1) + \" loaded successfully, id = \" + rets[i].id);\n    } else {\n      console.log(\"#\" + (i+1) + \" error occurred, message = \" + rets[i].errors.join(', '));\n    }\n  }\n  // ...\n});\n\n// same as following calls\nconn.sobject(\"Account\").insertBulk(accounts, function(err, rets) {\n  // ...\n});\n\n// \nconn.sobject(\"Account\").bulkload(\"insert\").execute(accounts, function(err, rets) {\n  // ...\n});\n```\n\n### Loading CSV file\n\n```javascript\n// CSV file to upload\nvar csvFileIn = require('fs').createReadStream(\"path/to/Account.csv\");\n\n// Create bulkload job and add batch to execute loading,\nvar job = conn.bulk.createJob(\"Account\", \"insert\");\nvar batch = job.createBatch();\nbatch.on(\"queue\", function(batchInfo) { // fired when batch request is queued in server.\n  batchId = batchInfo.id);\n  jobId = batchInfo.jobId);\n  // ...\n});\n\n// connect any readable stream via pipe method\ncsvFileIn.pipe(batch.stream());\n\n\n// or use Bulk#load() method in one call to upload file and fetch results. \nconn.bulk.load(\"Account\", \"insert\", csvFileIn, function(err, rets) {\n  if (err) { return console.error(err); }\n  for (var i=0; i < rets.length; i++) {\n    if (rets[i].success) {\n      console.log(\"#\" + (i+1) + \" loaded successfully, id = \" + rets[i].id);\n    } else {\n      console.log(\"#\" + (i+1) + \" error occurred, message = \" + rets[i].errors.join(', '));\n    }\n  }\n  // ...\n});\n\n\n```\n\n## Record Stream Pipeline\n\nRecord stream is a stream system which regards records in its stream, similar to Node.js's standard readable/writable streams.\n\nQuery object returned by Connection#query() / SObject#find() method is considered as InputRecordStream which emits event \"record\" when received record from server.\n\nBatch object returned by Job#createBatch() / Bulk#load() / SObject#bulkload() method is considered as OutputRecordStream and have send() and end() method to accept incoming record.\n\nYou can use InputRecordStream#pipe(outputRecordStream) to pipe record stream.\n\nRecordStream can be converted to usual Node.js's stream object by calling RecordStream#stream() method.\nBy default (and only currently) records are serizalized to CSV string.\n\n### Piping Query Record Stream\n\n```javascript\n// DELETE FROM Account WHERE CreatedDate < LAST_YEAR\nvar Account = conn.sobject('Account');\nAccount.find({ CreatedDate: { $lt: sf.Date.LAST_YEAR }})\n       .pipe(Account.deleteBulk())\n       .on('response', function(rets){\n         // ...\n       })\n       .on('error', function(err) {\n         // ...\n       });\n\n// UPDATE Opportunity SET Name = Accout.Name + ' - ' + Name WHERE Account.Id = :accId\nvar Opportunity = conn.sobject('Opportunity');\nOpportunity.find({ \"Account.Id\" : accId },\n                 { Id: 1, Name: 1, \"Account.Name\": 1 })\n           .pipe(sf.RecordStream.map(function(r) {\n             r.Name = r.Account.Name + ' - ' + r.Name;\n             return r;\n           }))\n           .pipe(Opportunity.updateBulk())\n           .on('response', function(rets) {\n             // ...\n           })\n           .on('error', function(err) {\n             // ...\n           });\n\n// Export all account records to CSV file\nvar csvFileOut = require('fs').createWriteStream('path/to/Account.csv');\nconn.query(\"SELECT Id, Name, Type, BillingState, BillingCity, BillingStreet FROM Account\")\n    .stream() // Convert to Node.js's usual readable stream.\n    .pipe(csvFileOut);\n\n```\n\n### Record Stream Filters\n\n```javascript\n// Map record and pass to downstream\nconn.sobject('Contact')\n    .find({}, { Id: 1, Name: 1 })\n    .pipe(sf.RecordStream.map(function(r) {\n      return { ID: r.Id, FULL_NAME: r.Name }\n    }))\n    .stream().pipe(fs.createWriteStream(\"Contact.csv\"));\n\n// Filter only matching record to pass downstream\nvar emails = {};\nconn.sobject('Lead')\n    .find({}, { Id: 1, Name: 1, Company: 1, Email: 1 })\n    .pipe(sf.RecordStream.filter(function(r) {\n      var dup = emails[r.Email];\n      if (!dup) { emails[r.Email] = true; }\n      return !dup;\n    }))\n    .stream().pipe(fs.createWriteStream(\"Lead.csv\"));\n```\n\n### Data Migration using Bulkload Batch Record Stream\n\n```javascript\n\n// Connection for org which migrating data from\nvar conn1 = new sf.Connection(\n  // ...\n);\n\n// Connection for org which migrating data to\nvar conn2 = new sf.Connection(\n  // ...\n);\n\nvar query = conn1.query(\"SELECT Id, Name, Type, BillingState, BillingCity, BillingStreet FROM Account\");\nvar job = conn2.bulk.createJob(\"Account\", \"insert\");\nvar batch = job.createBatch();\nquery.pipe(batch);\nbatch.on('queue', function() {\n  jobId = job.id;\n  batchId = batch.id;\n  //...\n})\n\n```\n\n\n## Change History\n\nv0.5.1 (Jan 11, 2013):\n\n* Move Query#stream() method to RecordStream#stream() to support stream serialization even in filtered stream.\n\nv0.5.0 (Jan 11, 2013):\n\n* Support Bulk API for insert/update/upsert/delete/hardDelete operation (except for 'query').\n\n* Refine Query#pipe to pipe to other output record stream (like bulk upload batch).\n\n* Add Query#stream() method to convert record stream to general node.js readable stream (generates CSV data).\n\n\nv0.4.0 (Nov 05, 2012):\n\n* Support JSON-style query object to query records other than SOQL, inspired by MongoDB query interface.\n\n* Change default API version to 26.0 (Winter '13).\n\n* Return logged-in user info in the callback response of Connection#login() and Connection#authorize().\n\n* Add Connection#logout() method to terminate session explicitly (Note: only useful for SOAP API login session).\n\n\nv0.3.4 (Oct 19, 2012):\n\n* Fix issue to refresh access token multiple time in concurrent requests.\n\n* Change to use \"Bearer\", not \"OAuth\" in HTTP Authorization header to attach access token.\n\n* Separate oauth2 configuration into different hash object in connection constructor option\n (old style is still supported for backward compatiblity).\n\n\nv0.3.2 (Oct 18, 2012):\n\n* Fix error handling in access token refresh flow.\n\n\nv0.3.1 (Jun 26, 2012):\n\n* Add support of Node.js 0.8.x.\n\n\nv0.3.0 (May 10, 2012):\n\n* Support Salesforce Streaming API.\n\n\n\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/stomita/node-salesforce/issues"
  },
  "_id": "node-salesforce@0.5.1",
  "dist": {
    "shasum": "bbea770968ea2c4c34a5ebbe8817ad602122288a"
  },
  "_from": "node-salesforce@0.5.1",
  "_resolved": "https://registry.npmjs.org/node-salesforce/-/node-salesforce-0.5.1.tgz"
}
